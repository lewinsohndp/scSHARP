{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5d0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gcn_model import GCNModel\n",
    "import utilities\n",
    "from test_model import test_model\n",
    "import os\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed56d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.8_de_rq/\"\n",
    "data_folder = \"simulations/splat_0.7_de_rq/\"\n",
    "# get labels\n",
    "data_path = data_folder + \"query_counts.csv\"\n",
    "tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "#tools = [\"scsorter\",\"scina\",\"singler\"]\n",
    "ref_path = data_folder + \"ref_counts.csv\"\n",
    "ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "marker_path = data_folder + \"markers.txt\"\n",
    "if os.path.exists(data_folder + \"preds.csv\"):\n",
    "    all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "    if all_labels.shape[1] != len(tools): \n",
    "        all_labels = all_labels[tools]\n",
    "        #raise Exception(\"wrong amount of tools in file\")\n",
    "else:\n",
    "    all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)\n",
    "\n",
    "# read in dataset\n",
    "X = pd.read_csv(data_path, index_col=0)\n",
    "X, keep_cells,_,_ = utilities.preprocess(np.array(X), scale=False, comps=500)\n",
    "\n",
    "all_labels = all_labels.loc[keep_cells,:]\n",
    "\n",
    "_,marker_names = utilities.read_marker_file(marker_path)\n",
    "\n",
    "all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "\n",
    "meta_path = data_folder + \"query_meta.csv\"\n",
    "metadata = pd.read_csv(meta_path, index_col=0)\n",
    "real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "real_y = real_y[keep_cells]\n",
    "\n",
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = .51)\n",
    "\n",
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b15fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01173e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7541c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 25.843058\n",
      "Loss in epoch 10 = 0.073158\n",
      "Loss in epoch 20 = 0.017070\n",
      "Loss in epoch 30 = 0.009762\n",
      "Loss in epoch 40 = 0.004732\n",
      "Loss in epoch 50 = 0.002694\n",
      "Loss in epoch 60 = 0.002010\n",
      "Loss in epoch 70 = 0.001146\n",
      "Loss in epoch 80 = 0.000985\n",
      "Loss in epoch 90 = 0.000842\n",
      "Loss in epoch 100 = 0.000619\n",
      "Loss in epoch 110 = 0.000556\n",
      "Loss in epoch 120 = 0.000495\n",
      "Loss in epoch 130 = 0.000373\n",
      "Loss in epoch 140 = 0.000319\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, dropout=0.0)\n",
    "m.train(dataloader, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3c5fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9579579830169678,\n",
       " array([[214,  10,   2,   6],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  0,   3, 227,   4],\n",
       "        [  1,   5,   8, 251]]),\n",
       " 0.9702315330505371,\n",
       " array([[173,   7,   2,   2],\n",
       "        [  0, 264,   2,   1],\n",
       "        [  0,   3, 208,   1],\n",
       "        [  0,   3,   6, 235]]),\n",
       " 0.8369565010070801,\n",
       " array([[41,  3,  0,  4],\n",
       "        [ 0,  1,  0,  0],\n",
       "        [ 0,  0, 19,  3],\n",
       "        [ 1,  2,  2, 16]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d331ca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.95918369, 1.        , 0.81632656],\n",
       "       [1.        , 1.        , 0.97354496, 1.        , 0.78835976],\n",
       "       [1.        , 1.        , 0.93129772, 1.        , 0.87022901],\n",
       "       [1.        , 1.        , 1.        , 1.        , 0.76543212]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tool weights by cell\n",
    "ultra_confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = .9)\n",
    "ultra_conf_nodes = np.where(ultra_confident_labels != -1)[0]\n",
    "weights = np.zeros((4,5))\n",
    "for type in [0,1,2,3]:\n",
    "    \n",
    "    type_indices = np.where(confident_labels[ultra_conf_nodes]==type)[0]\n",
    "    for i, tool in enumerate(tools):\n",
    "        weights[type,i] = utilities.pred_accuracy(all_labels_factored[tool].to_numpy()[ultra_conf_nodes][type_indices], confident_labels[ultra_conf_nodes][type_indices])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20077278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n",
      "multiple maxes\n"
     ]
    }
   ],
   "source": [
    "new_encoded = utilities.weighted_encode(all_labels_factored, encoded_labels, weights,.5)\n",
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = .51)\n",
    "\n",
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dc21a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4288f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647460e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 26.061798\n",
      "Loss in epoch 10 = 0.071316\n",
      "Loss in epoch 20 = 0.019366\n",
      "Loss in epoch 30 = 0.006830\n",
      "Loss in epoch 40 = 0.004786\n",
      "Loss in epoch 50 = 0.002491\n",
      "Loss in epoch 60 = 0.002129\n",
      "Loss in epoch 70 = 0.001528\n",
      "Loss in epoch 80 = 0.001012\n",
      "Loss in epoch 90 = 0.000689\n",
      "Loss in epoch 100 = 0.000599\n",
      "Loss in epoch 110 = 0.000556\n",
      "Loss in epoch 120 = 0.000393\n",
      "Loss in epoch 130 = 0.000327\n",
      "Loss in epoch 140 = 0.000350\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, dropout=0.0)\n",
    "m.train(dataloader, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac4d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9589589834213257,\n",
       " array([[211,  11,   2,   8],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  0,   4, 228,   2],\n",
       "        [  1,   4,   6, 254]]),\n",
       " 0.9702315330505371,\n",
       " array([[173,   7,   2,   2],\n",
       "        [  0, 264,   2,   1],\n",
       "        [  0,   3, 208,   1],\n",
       "        [  0,   3,   6, 235]]),\n",
       " 0.8478260636329651,\n",
       " array([[38,  4,  0,  6],\n",
       "        [ 0,  1,  0,  0],\n",
       "        [ 0,  1, 20,  1],\n",
       "        [ 1,  1,  0, 19]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b0166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,_ = m.predict(test_dataloader)\n",
    "final_preds = preds.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba66bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 3, 0, 0, 3, 2, 0, 3, 0, 0, 2, 0, 0,\n",
       "       0, 0, 2, 2, 0, 2, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c19b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 1, 3, 3, 3, 0, 3, 2, 3, 0, 0, 2, 2, 0, 3, 0, 0, 2, 0, 0, 0, 2,\n",
       "        2, 2, 0, 2, 0, 2], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6414c58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9968, 0.9425, 0.5502, 0.9494, 0.9739, 0.9985, 0.9989, 0.8702,\n",
       "        0.7334, 0.9981, 0.9445, 0.5272, 0.5079, 0.9870, 0.9995, 0.9896, 0.9990,\n",
       "        0.9985, 0.7850, 0.9972, 0.7456, 0.5415, 0.6565, 0.9933, 0.9968, 0.9990,\n",
       "        0.9982, 0.7832, 0.9412], device='cuda:0', grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[test_nodes]\n",
    "preds.max(dim=1)[0][test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff178405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.5888888955116272\n",
      "0.06136311310462684\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = [0]*5\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    m = GCNModel(\"configs/test18.txt\", 2, dropout=0.1)\n",
    "    m.train(dataloader, 150, verbose=False)\n",
    "    _,_,_,_,acc,_ = m.validation_metrics(test_dataloader, train_nodes, test_nodes)\n",
    "    test_accuracy[i] = acc\n",
    "print(statistics.mean(test_accuracy))\n",
    "print(statistics.stdev(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

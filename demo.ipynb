{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniconda3/envs/sharp_test/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from scSHARP.sc_sharp import *\n",
    "from scSHARP.sc_sharp import scSHARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"simulations/splat_0.7/query_counts.csv.gz\"\n",
    "tool_preds = \"simulations/splat_0.7/preds.csv\"\n",
    "tool_list = [\"scina\", \"scsorter\", \"sctype\", \"scpred\", \"singler\"]\n",
    "marker_path = \"simulations/splat_0.7/markers.txt\"\n",
    "neighbors=2\n",
    "config=\"configs/2_25.txt\"\n",
    "sharp = scSHARP(data_path, tool_preds, tool_list, marker_path, neighbors, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 57.722404\n",
      "Loss in epoch 10 = 0.058697\n",
      "Loss in epoch 20 = 0.013447\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=8)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 57.722389\n",
      "Loss in epoch 10 = 0.058695\n",
      "Loss in epoch 20 = 0.013447\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run with updated pytorch versions\n",
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=8)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 57.722389\n",
      "Loss in epoch 10 = 0.058695\n",
      "Loss in epoch 20 = 0.013447\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run with updated pytorch versions 2\n",
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=8)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 57.722404\n",
      "Loss in epoch 10 = 0.058697\n",
      "Loss in epoch 20 = 0.013447\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=8)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 58.715343\n",
      "Loss in epoch 10 = 0.060942\n",
      "Loss in epoch 20 = 0.014680\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 0.9996, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=9)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 58.715343\n",
      "Loss in epoch 10 = 0.060942\n",
      "Loss in epoch 20 = 0.014680\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 0.9996, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=9)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 58.723263\n",
      "Loss in epoch 10 = 0.050313\n",
      "Loss in epoch 20 = 0.018438\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 58.723263\n",
      "Loss in epoch 10 = 0.050313\n",
      "Loss in epoch 20 = 0.018438\n",
      "tensor([0, 0, 2, 0, 3, 3, 1, 2, 1, 2])\n",
      "tensor([1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=30, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([0.3325, 0.3198, 0.3219, 0.3393, 0.3496, 0.3300, 0.3093, 0.3366, 0.3348,\n",
      "        0.3301], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([0.3325, 0.3198, 0.3219, 0.3393, 0.3496, 0.3300, 0.3093, 0.3366, 0.3348,\n",
      "        0.3301], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#updated torch\n",
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated torch 2\n",
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([0.3325, 0.3198, 0.3219, 0.3393, 0.3496, 0.3300, 0.3093, 0.3366, 0.3348,\n",
      "        0.3301], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=10)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 1, 1, 3, 3, 3, 3, 3, 3])\n",
      "tensor([0.2750, 0.3178, 0.2670, 0.2742, 0.3065, 0.2845, 0.2959, 0.2797, 0.2937,\n",
      "        0.2757], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=11)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 1, 1, 3, 3, 3, 3, 3, 3])\n",
      "tensor([0.2750, 0.3178, 0.2670, 0.2742, 0.3065, 0.2845, 0.2959, 0.2797, 0.2937,\n",
      "        0.2757], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds, train_nodes, test_nodes, keep_cells, conf_scores = sharp.run_prediction(training_epochs=0, thresh=0.51, batch_size=20, seed=11)\n",
    "print(preds[0:10])\n",
    "print(conf_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp.save_model(\"/Users/daniel/Desktop/example_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp.load_model(\"/Users/daniel/Desktop/example_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniconda3/envs/sharp_test_2/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/daniel/miniconda3/envs/sharp_test_2/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Group3</th>\n",
       "      <th>Group4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gene1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene2</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene3</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene9</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene33680</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene33681</th>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene33682</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene33688</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene33690</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15419 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Group1    Group2    Group3    Group4\n",
       "Gene1      0.000000  0.000000  0.000045  0.000086\n",
       "Gene2     -0.000009  0.000050 -0.000033  0.000098\n",
       "Gene3      0.000052  0.000001 -0.000023  0.000386\n",
       "Gene7      0.000000  0.000003  0.000000  0.000301\n",
       "Gene9     -0.000009 -0.000059  0.000053  0.000060\n",
       "...             ...       ...       ...       ...\n",
       "Gene33680  0.000000  0.000027  0.000000  0.000276\n",
       "Gene33681 -0.000233  0.001898 -0.000114 -0.000072\n",
       "Gene33682  0.000055 -0.000060 -0.000014  0.000586\n",
       "Gene33688  0.000066 -0.000003  0.000082  0.000141\n",
       "Gene33690  0.000019  0.000148 -0.000003 -0.000045\n",
       "\n",
       "[15419 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df = sharp.run_interpretation()\n",
    "int_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('sharp_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e58e873d7ffda574a5fa405c09f1a318ac42e692a952fce926fb93d59d47bba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gcn_model import GCNModel\n",
    "import utilities\n",
    "from test_model import test_model\n",
    "import os\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq_v3/\"\n",
    "data_folder = \"simulations/splat_0.7_de_rq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "data_path = data_folder + \"query_counts.csv\"\n",
    "tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "#tools = [\"scsorter\",\"scina\",\"singler\"]\n",
    "ref_path = data_folder + \"ref_counts.csv\"\n",
    "ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "marker_path = data_folder + \"markers.txt\"\n",
    "if os.path.exists(data_folder + \"preds.csv\"):\n",
    "    all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "    if all_labels.shape[1] != len(tools): \n",
    "        all_labels = all_labels[tools]\n",
    "        #raise Exception(\"wrong amount of tools in file\")\n",
    "else:\n",
    "    all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataset\n",
    "X = pd.read_csv(data_path, index_col=0)\n",
    "X, keep_cells, keep_genes, rpca = utilities.preprocess(np.array(X), scale=False)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.loc[keep_cells,:]\n",
    "_,marker_names = utilities.read_marker_file(marker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = .51)\n",
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(len(tools))\n",
    "for i, tool in enumerate(tools):\n",
    "    scores[i] = utilities.pred_accuracy(all_labels_factored[tool].to_numpy()[train_nodes], confident_labels[train_nodes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85556781, 0.88643879, 0.85997796, 0.88313121, 0.65711135])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57722352, -1.5417768 , -1.57208211, -1.54551509, -1.84113539])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores /= scores.sum()\n",
    "scores = np.log(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2065, 0.2140, 0.2076, 0.2132, 0.1586], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor(scores),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_labels_factored.to_numpy()\n",
    "results_exp = np.zeros((results.shape[0], results.shape[1], 4))\n",
    "\n",
    "results_exp[results == 0, :] = np.array([1,0,0,0])\n",
    "results_exp[results == 1, :] = np.array([0,1,0,0])\n",
    "results_exp[results == 2, :] = np.array([0,0,1,0])\n",
    "results_exp[results == 3, :] = np.array([0,0,0,1])\n",
    "\n",
    "tY = torch.tensor(results_exp).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = data_folder + \"query_meta.csv\"\n",
    "metadata = pd.read_csv(meta_path, index_col=0)\n",
    "real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "real_y = real_y[keep_cells]\n",
    "real_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/m7t63tn57zj6156pfxpr2bhw0000gn/T/ipykernel_67491/3616995915.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(tY))\n"
     ]
    }
   ],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(tY))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, scores, weights_mode = True, learn_weights = False, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 12.064449\n",
      "Loss in epoch 10 = 4.499492\n",
      "Loss in epoch 20 = 4.263627\n",
      "Loss in epoch 30 = 4.201023\n",
      "Loss in epoch 40 = 4.147159\n",
      "Loss in epoch 50 = 4.122489\n",
      "Loss in epoch 60 = 4.110283\n",
      "Loss in epoch 70 = 4.088551\n",
      "Loss in epoch 80 = 4.090820\n",
      "Loss in epoch 90 = 4.075344\n",
      "Loss in epoch 100 = 4.056178\n",
      "Loss in epoch 110 = 4.065664\n",
      "Loss in epoch 120 = 4.046824\n",
      "Loss in epoch 130 = 4.044737\n",
      "Loss in epoch 140 = 4.041814\n"
     ]
    }
   ],
   "source": [
    "m.train(dataloader, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9319319128990173,\n",
       " array([[199,  17,  11,   5],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  3,   6, 221,   4],\n",
       "        [  2,   6,  11, 246]]),\n",
       " 0.9702315330505371,\n",
       " array([[173,   7,   2,   2],\n",
       "        [  0, 264,   2,   1],\n",
       "        [  0,   3, 208,   1],\n",
       "        [  0,   3,   6, 235]]),\n",
       " 0.554347813129425,\n",
       " array([[26, 10,  9,  3],\n",
       "        [ 0,  1,  0,  0],\n",
       "        [ 3,  3, 13,  3],\n",
       "        [ 2,  3,  5, 11]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 26.071560\n",
      "Loss in epoch 10 = 0.066667\n",
      "Loss in epoch 20 = 0.014319\n",
      "Loss in epoch 30 = 0.007804\n",
      "Loss in epoch 40 = 0.004762\n",
      "Loss in epoch 50 = 0.003824\n",
      "Loss in epoch 60 = 0.002068\n",
      "Loss in epoch 70 = 0.001413\n",
      "Loss in epoch 80 = 0.001221\n",
      "Loss in epoch 90 = 0.001055\n",
      "Loss in epoch 100 = 0.000549\n",
      "Loss in epoch 110 = 0.000465\n",
      "Loss in epoch 120 = 0.000501\n",
      "Loss in epoch 130 = 0.000378\n",
      "Loss in epoch 140 = 0.000349\n",
      "Loss in epoch 150 = 0.000510\n",
      "Loss in epoch 160 = 0.000215\n",
      "Loss in epoch 170 = 0.000199\n",
      "Loss in epoch 180 = 0.000140\n",
      "Loss in epoch 190 = 0.000132\n",
      "Loss in epoch 200 = 0.000244\n",
      "Loss in epoch 210 = 0.000103\n",
      "Loss in epoch 220 = 0.000077\n",
      "Loss in epoch 230 = 0.000095\n",
      "Loss in epoch 240 = 0.000073\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, scores, weights_mode = False, learn_weights = False, dropout=0.0)\n",
    "m.train(dataloader, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.955955982208252,\n",
       " array([[211,  10,   2,   9],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  2,   3, 224,   5],\n",
       "        [  1,   3,   6, 255]]),\n",
       " 0.9702315330505371,\n",
       " array([[173,   7,   2,   2],\n",
       "        [  0, 264,   2,   1],\n",
       "        [  0,   3, 208,   1],\n",
       "        [  0,   3,   6, 235]]),\n",
       " 0.8152173757553101,\n",
       " array([[38,  3,  0,  7],\n",
       "        [ 0,  1,  0,  0],\n",
       "        [ 2,  0, 16,  4],\n",
       "        [ 1,  0,  0, 20]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

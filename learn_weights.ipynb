{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/.conda/envs/daniel_thesis_2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gcn_model import GCNModel\n",
    "import utilities\n",
    "from test_model import test_model\n",
    "import os\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\"\n",
    "#data_folder = \"simulations/splat_0.7_de_rq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "data_path = data_folder + \"query_counts.csv\"\n",
    "tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "#tools = [\"scsorter\",\"scina\",\"singler\", \"sctype\"]\n",
    "ref_path = data_folder + \"ref_counts.csv\"\n",
    "ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "marker_path = data_folder + \"markers.txt\"\n",
    "if os.path.exists(data_folder + \"preds.csv\"):\n",
    "    all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "    if all_labels.shape[1] != len(tools): \n",
    "        all_labels = all_labels[tools]\n",
    "        #raise Exception(\"wrong amount of tools in file\")\n",
    "else:\n",
    "    all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataset\n",
    "X = pd.read_csv(data_path, index_col=0)\n",
    "X, keep_cells, keep_genes, rpca = utilities.preprocess(np.array(X), scale=False)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.loc[keep_cells,:]\n",
    "_,marker_names = utilities.read_marker_file(marker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = .51)\n",
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(len(tools))\n",
    "for i, tool in enumerate(tools):\n",
    "    scores[i] = utilities.pred_accuracy(all_labels_factored[tool].to_numpy()[train_nodes], confident_labels[train_nodes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8512035 , 0.89168489, 0.85557985, 0.87527353, 0.68818378])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58708189, -1.54062031, -1.58195369, -1.55919668, -1.79967719])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores /= scores.sum()\n",
    "scores = np.log(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2045, 0.2142, 0.2056, 0.2103, 0.1654], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor(scores),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_labels_factored.to_numpy()\n",
    "results_exp = np.zeros((results.shape[0], results.shape[1], 4))\n",
    "\n",
    "results_exp[results == 0, :] = np.array([1,0,0,0])\n",
    "results_exp[results == 1, :] = np.array([0,1,0,0])\n",
    "results_exp[results == 2, :] = np.array([0,0,1,0])\n",
    "results_exp[results == 3, :] = np.array([0,0,0,1])\n",
    "\n",
    "tY = torch.tensor(results_exp).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = data_folder + \"query_meta.csv\"\n",
    "metadata = pd.read_csv(meta_path, index_col=0)\n",
    "real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "real_y = real_y[keep_cells]\n",
    "real_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [ 42, 178,   7,   2,   3],\n",
       "       [  2,   0, 264,   2,   0],\n",
       "       [ 16,   1,   2, 214,   1],\n",
       "       [ 25,   0,   5,   4, 231]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(real_y, confident_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186,  12,   9,  25],\n",
       "       [  2, 248,   5,  13],\n",
       "       [  9,   8, 196,  21],\n",
       "       [ 21,  31,  30, 183]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(real_y, all_labels_factored[\"sctype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-5609dd3d85d1>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(tY))\n"
     ]
    }
   ],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(tY))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 12.690382\n",
      "Loss in epoch 10 = 4.394219\n",
      "Loss in epoch 20 = 4.067180\n",
      "Loss in epoch 30 = 4.004829\n",
      "Loss in epoch 40 = 3.942397\n",
      "Loss in epoch 50 = 3.873939\n",
      "Loss in epoch 60 = 3.844952\n",
      "Loss in epoch 70 = 3.808426\n",
      "Loss in epoch 80 = 3.789386\n",
      "Loss in epoch 90 = 3.783088\n",
      "Loss in epoch 100 = 3.779667\n",
      "Loss in epoch 110 = 3.760251\n",
      "Loss in epoch 120 = 3.760436\n",
      "Loss in epoch 130 = 3.764865\n",
      "Loss in epoch 140 = 3.756975\n",
      "Loss in epoch 150 = 3.757146\n",
      "Loss in epoch 160 = 3.747303\n",
      "Loss in epoch 170 = 3.746152\n",
      "Loss in epoch 180 = 3.740202\n",
      "Loss in epoch 190 = 3.739523\n",
      "Loss in epoch 200 = 3.731399\n",
      "Loss in epoch 210 = 3.739038\n",
      "Loss in epoch 220 = 3.732474\n",
      "Loss in epoch 230 = 3.742904\n",
      "Loss in epoch 240 = 3.726575\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, scores, weights_mode = True, learn_weights = True, dropout=0.0)\n",
    "m.train(dataloader, 250, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.935935914516449,\n",
       " array([[198,  15,   8,  11],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  2,   6, 223,   3],\n",
       "        [  0,   7,   9, 249]]),\n",
       " 0.970459520816803,\n",
       " array([[178,   7,   2,   3],\n",
       "        [  0, 264,   2,   0],\n",
       "        [  1,   2, 214,   1],\n",
       "        [  0,   5,   4, 231]]),\n",
       " 0.5647059082984924,\n",
       " array([[20,  8,  6,  8],\n",
       "        [ 0,  1,  0,  1],\n",
       "        [ 1,  4,  9,  2],\n",
       "        [ 0,  2,  5, 18]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.935935914516449, array([[201,  14,   8,   9],\n",
      "       [  0, 266,   2,   0],\n",
      "       [  2,   5, 221,   6],\n",
      "       [  4,   5,   9, 247]]), 0.9693654179573059, array([[178,   7,   2,   3],\n",
      "       [  0, 264,   2,   0],\n",
      "       [  1,   2, 214,   1],\n",
      "       [  1,   5,   4, 230]]), 0.5764706134796143, array([[23,  7,  6,  6],\n",
      "       [ 0,  2,  0,  0],\n",
      "       [ 1,  3,  7,  5],\n",
      "       [ 3,  0,  5, 17]]))\n",
      "(0.9289289116859436, array([[198,  17,   9,   8],\n",
      "       [  0, 266,   2,   0],\n",
      "       [  3,   5, 221,   5],\n",
      "       [  1,  11,  10, 243]]), 0.970459520816803, array([[178,   7,   2,   3],\n",
      "       [  0, 264,   2,   0],\n",
      "       [  1,   2, 214,   1],\n",
      "       [  0,   5,   4, 231]]), 0.48235294222831726, array([[20, 10,  7,  5],\n",
      "       [ 0,  2,  0,  0],\n",
      "       [ 2,  3,  7,  4],\n",
      "       [ 1,  6,  6, 12]]))\n",
      "(0.9219219088554382, array([[196,  14,  12,  10],\n",
      "       [  0, 264,   3,   1],\n",
      "       [  4,   7, 218,   5],\n",
      "       [  0,  10,  12, 243]]), 0.970459520816803, array([[178,   7,   2,   3],\n",
      "       [  0, 264,   2,   0],\n",
      "       [  1,   2, 214,   1],\n",
      "       [  0,   5,   4, 231]]), 0.4000000059604645, array([[18,  7, 10,  7],\n",
      "       [ 0,  0,  1,  1],\n",
      "       [ 3,  5,  4,  4],\n",
      "       [ 0,  5,  8, 12]]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    m = GCNModel(\"configs/2_40.txt\", 2, scores, weights_mode = True, learn_weights = True, dropout=0.0)\n",
    "    m.train(dataloader, 250, verbose=False)\n",
    "    print(m.validation_metrics(test_dataloader, train_nodes, test_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 26.129650\n",
      "Loss in epoch 10 = 0.062354\n",
      "Loss in epoch 20 = 0.017898\n",
      "Loss in epoch 30 = 0.007746\n",
      "Loss in epoch 40 = 0.004978\n",
      "Loss in epoch 50 = 0.002958\n",
      "Loss in epoch 60 = 0.001911\n",
      "Loss in epoch 70 = 0.001794\n",
      "Loss in epoch 80 = 0.001034\n",
      "Loss in epoch 90 = 0.000938\n",
      "Loss in epoch 100 = 0.000736\n",
      "Loss in epoch 110 = 0.000646\n",
      "Loss in epoch 120 = 0.000430\n",
      "Loss in epoch 130 = 0.000282\n",
      "Loss in epoch 140 = 0.000286\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, scores, weights_mode = False, learn_weights = False, dropout=0.0)\n",
    "m.train(dataloader, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9579579830169678,\n",
       " array([[212,  10,   2,   8],\n",
       "        [  0, 266,   2,   0],\n",
       "        [  2,   3, 227,   2],\n",
       "        [  1,   7,   5, 252]]),\n",
       " 0.970459520816803,\n",
       " array([[178,   7,   2,   3],\n",
       "        [  0, 264,   2,   0],\n",
       "        [  1,   2, 214,   1],\n",
       "        [  0,   5,   4, 231]]),\n",
       " 0.8235294222831726,\n",
       " array([[34,  3,  0,  5],\n",
       "        [ 0,  2,  0,  0],\n",
       "        [ 1,  1, 13,  1],\n",
       "        [ 1,  2,  1, 21]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel_thesis",
   "language": "python",
   "name": "daniel_thesis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

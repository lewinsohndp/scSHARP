{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca_model import PCAModel\n",
    "from gcn_model import GCNModel\n",
    "import utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients, DeepLift, DeepLiftShap, FeaturePermutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"simulations/splat_0.7_de_rq/\"\n",
    "data_path = data_folder + \"query_counts.csv\"\n",
    "marker_path = data_folder + \"markers.txt\"\n",
    "# read in dataset\n",
    "counts = pd.read_csv(data_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.1202,  4.9487,  0.0848,  ..., -0.4235,  0.8613, -1.8527],\n",
       "        [-0.2812, -1.5428,  3.2285,  ..., -0.2027, -0.5386, -2.4170],\n",
       "        [-2.1465, -0.3854, -1.0680,  ..., -0.8622,  1.8184,  0.8735],\n",
       "        ...,\n",
       "        [ 6.4777, -1.0975,  0.5996,  ..., -0.1975,  0.5876,  0.2261],\n",
       "        [-6.2502, -2.2448,  2.3801,  ...,  0.5046, -0.0493,  0.1208],\n",
       "        [-5.9382,  4.7989, -0.2715,  ..., -0.6843, -0.5246,  1.3884]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,_,_,_ = utilities.preprocess(np.array(counts), scale=False, run_pca=False)\n",
    "pca = PCA(n_components=500, random_state=8)\n",
    "new_data = pca.fit(X)\n",
    "pca_mod = PCAModel(pca.components_, pca.mean_)\n",
    "pca_mod(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.12022   ,  4.948713  ,  0.08479678, ..., -0.42349264,\n",
       "         0.861268  , -1.8526838 ],\n",
       "       [-0.28116703, -1.5429112 ,  3.2285054 , ..., -0.2027156 ,\n",
       "        -0.5385919 , -2.4170127 ],\n",
       "       [-2.1465366 , -0.3853437 , -1.0680304 , ..., -0.8622164 ,\n",
       "         1.8183985 ,  0.87353873],\n",
       "       ...,\n",
       "       [ 6.477684  , -1.0975296 ,  0.5995855 , ..., -0.19748206,\n",
       "         0.587635  ,  0.22611101],\n",
       "       [-6.2502413 , -2.2447553 ,  2.380058  , ...,  0.50463355,\n",
       "        -0.04931175,  0.12082425],\n",
       "       [-5.938177  ,  4.798928  , -0.2715307 , ..., -0.6843324 ,\n",
       "        -0.5246253 ,  1.3883908 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, keep_cells, keep_genes, rpca = utilities.preprocess(np.array(counts), scale=False, comps=500)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = counts.columns.to_numpy()[keep_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "all_labels = all_labels.loc[keep_cells,:]\n",
    "\n",
    "_,marker_names = utilities.read_marker_file(marker_path)\n",
    "\n",
    "all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "\n",
    "meta_path = data_folder + \"query_meta.csv\"\n",
    "metadata = pd.read_csv(meta_path, index_col=0)\n",
    "real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "real_y = real_y[keep_cells]\n",
    "\n",
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "\n",
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n",
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 26.021423\n",
      "Loss in epoch 10 = 0.069141\n",
      "Loss in epoch 20 = 0.014639\n",
      "Loss in epoch 30 = 0.008954\n",
      "Loss in epoch 40 = 0.004932\n",
      "Loss in epoch 50 = 0.002885\n",
      "Loss in epoch 60 = 0.001884\n",
      "Loss in epoch 70 = 0.001322\n",
      "Loss in epoch 80 = 0.001180\n",
      "Loss in epoch 90 = 0.001211\n",
      "Loss in epoch 100 = 0.000603\n",
      "Loss in epoch 110 = 0.000499\n",
      "Loss in epoch 120 = 0.000556\n",
      "Loss in epoch 130 = 0.000350\n",
      "Loss in epoch 140 = 0.000364\n"
     ]
    }
   ],
   "source": [
    "m = GCNModel(\"configs/2_40.txt\", 2, target_types=4)\n",
    "m.train(dataloader, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9579579830169678,\n",
       " array([[212,  10,   3,   7],\n",
       "        [  0, 265,   2,   1],\n",
       "        [  1,   3, 227,   3],\n",
       "        [  1,   4,   7, 253]]),\n",
       " 0.9722838401794434,\n",
       " array([[172,   7,   2,   1],\n",
       "        [  0, 264,   2,   1],\n",
       "        [  0,   2, 206,   1],\n",
       "        [  0,   3,   6, 235]]),\n",
       " 0.8247422575950623,\n",
       " array([[40,  3,  1,  6],\n",
       "        [ 0,  1,  0,  0],\n",
       "        [ 1,  1, 21,  2],\n",
       "        [ 1,  1,  1, 18]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds,_ = m.predict(test_dataloader)\n",
    "final_preds = preds.max(dim=1)[1]\n",
    "utilities.validation_metrics(torch.tensor(real_y), final_preds, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "old_int_df = utilities.run_interpretation(m, X, rpca, final_preds, gene_names, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,_,_,_ = utilities.preprocess(np.array(counts), scale=False, run_pca=False)\n",
    "pca = PCA(n_components=500, random_state=8)\n",
    "new_data = pca.fit(X)\n",
    "pca_mod = PCAModel(pca.components_, pca.mean_)\n",
    "seq = torch.nn.Sequential(pca_mod, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/m7t63tn57zj6156pfxpr2bhw0000gn/T/ipykernel_2603/1437327079.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(final_preds))\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(final_preds))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.0002e-07, 9.4203e-09, 3.0960e-07],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9259e-08, 1.0000e+00, 2.9075e-06, 1.2897e-06],\n",
      "        [2.0151e-07, 1.0000e+00, 4.2631e-08, 4.4288e-06],\n",
      "        [3.6708e-01, 1.3469e-01, 1.2522e-03, 4.9698e-01],\n",
      "        [1.6632e-06, 1.3857e-09, 1.4777e-06, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0002e-07, 9.4204e-09, 3.0961e-07],\n",
      "        [7.5070e-08, 2.0073e-07, 7.4459e-09, 1.0000e+00],\n",
      "        [1.2477e-06, 4.2179e-07, 2.3893e-07, 1.0000e+00],\n",
      "        [1.6091e-04, 9.0509e-04, 7.2134e-05, 9.9886e-01],\n",
      "        [2.4107e-06, 9.9999e-01, 7.7663e-07, 3.5167e-06],\n",
      "        [1.0000e+00, 3.5011e-08, 5.9320e-07, 1.9135e-08],\n",
      "        [1.4316e-06, 1.0137e-08, 1.0000e+00, 3.8611e-08],\n",
      "        [4.3361e-08, 1.8669e-06, 1.8195e-06, 1.0000e+00],\n",
      "        [5.0158e-07, 6.1181e-06, 1.1746e-07, 9.9999e-01],\n",
      "        [9.9997e-01, 6.0984e-06, 1.8858e-05, 5.8216e-06],\n",
      "        [2.0476e-06, 3.5836e-06, 2.2832e-07, 9.9999e-01],\n",
      "        [4.2486e-02, 3.3917e-04, 1.7764e-05, 9.5716e-01],\n",
      "        [1.0423e-06, 2.7161e-07, 4.3051e-08, 1.0000e+00],\n",
      "        [9.9999e-01, 6.7291e-06, 1.3702e-06, 4.2909e-06],\n",
      "        [7.6498e-09, 2.1823e-08, 1.0000e+00, 1.8797e-09],\n",
      "        [2.4373e-07, 4.2716e-07, 1.0000e+00, 2.3370e-07],\n",
      "        [2.5623e-08, 6.0633e-09, 1.0000e+00, 4.4905e-06],\n",
      "        [1.0959e-07, 1.0000e+00, 9.7193e-07, 4.6520e-09],\n",
      "        [6.6963e-07, 3.1466e-06, 1.0000e+00, 2.6808e-07],\n",
      "        [1.0000e+00, 4.4866e-08, 6.5904e-09, 1.4496e-07],\n",
      "        [9.9997e-01, 3.6213e-06, 1.2926e-05, 9.0441e-06],\n",
      "        [9.3613e-09, 1.0000e+00, 3.6988e-07, 6.2457e-07],\n",
      "        [1.0000e+00, 2.2622e-06, 6.6985e-07, 8.1241e-07],\n",
      "        [1.0000e+00, 1.4939e-07, 5.2174e-07, 8.6408e-07],\n",
      "        [1.3290e-06, 2.1010e-07, 3.4787e-08, 1.0000e+00],\n",
      "        [4.3683e-08, 7.0018e-07, 3.5451e-07, 1.0000e+00],\n",
      "        [4.3556e-06, 6.2120e-08, 3.7644e-06, 9.9999e-01],\n",
      "        [6.1244e-09, 1.1472e-06, 1.0000e+00, 7.8515e-09],\n",
      "        [7.2944e-07, 1.7326e-08, 6.4198e-09, 1.0000e+00],\n",
      "        [3.4690e-01, 5.7988e-01, 7.1309e-02, 1.9086e-03],\n",
      "        [9.9999e-01, 3.1359e-06, 2.4666e-06, 2.6831e-09],\n",
      "        [1.0000e+00, 3.5096e-06, 1.5011e-07, 1.7615e-08],\n",
      "        [1.0000e+00, 2.5253e-07, 2.7536e-09, 4.5469e-08],\n",
      "        [7.2161e-07, 5.1345e-06, 9.1301e-07, 9.9999e-01],\n",
      "        [9.9998e-01, 1.6856e-05, 1.5751e-06, 5.5980e-07],\n",
      "        [2.4752e-08, 1.0000e+00, 2.5123e-08, 1.5697e-09],\n",
      "        [9.6942e-01, 5.0932e-05, 2.3469e-02, 7.0612e-03],\n",
      "        [9.9946e-01, 5.5282e-06, 5.3789e-04, 1.5210e-06],\n",
      "        [9.9996e-01, 1.5266e-07, 3.5672e-05, 6.9192e-08],\n",
      "        [7.1511e-09, 6.9048e-09, 9.1666e-09, 1.0000e+00],\n",
      "        [7.1185e-09, 7.5513e-06, 4.1906e-06, 9.9999e-01],\n",
      "        [1.5959e-06, 7.9573e-08, 1.0000e+00, 4.6815e-07],\n",
      "        [2.0570e-06, 4.0314e-06, 5.8054e-07, 9.9999e-01],\n",
      "        [4.3926e-08, 1.0000e+00, 4.7850e-08, 1.7580e-06],\n",
      "        [1.0000e+00, 4.5057e-08, 1.4892e-06, 5.8245e-08],\n",
      "        [9.9999e-01, 3.3531e-07, 2.4734e-06, 1.0069e-05]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1, 1, 3, 3, 0, 3, 3, 3, 1, 0, 2, 3, 3, 0, 3, 3, 3, 0, 2, 2, 2, 1, 2, 0,\n",
      "        0, 1, 0, 0, 3, 3, 3, 2, 3, 1, 0, 0, 0, 3, 0, 1, 0, 0, 0, 3, 3, 2, 3, 1,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    temp_preds = seq(X)\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    temp_preds = softmax(temp_preds)\n",
    "    print(temp_preds)\n",
    "    print(temp_preds.max(dim=1)[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dl = DeepLift(seq)\n",
    "attributions = np.zeros((X.shape[0], X.shape[1]))\n",
    "temp_atts = None\n",
    "for data,preds in test_dataloader:\n",
    "    #baseline = torch.FloatTensor(np.full(data.shape, X.min()))\n",
    "    baseline = torch.FloatTensor(np.zeros(data.shape))\n",
    "    #baseline = torch.FloatTensor(np.full(data.shape, X.max()))\n",
    "    temp = dl.attribute(data.to(m.device), baseline.to(m.device), target=preds.to(m.device), return_convergence_delta=True)[0]\n",
    "    #temp = dl.attribute(data.to(model.device), target=pred_name).cpu().detach()\n",
    "    if temp_atts == None: temp_atts = temp\n",
    "    else:\n",
    "        temp_atts = torch.cat((temp_atts, temp), 0)\n",
    "    \n",
    "attributions = temp_atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16186</th>\n",
       "      <th>16187</th>\n",
       "      <th>16188</th>\n",
       "      <th>16189</th>\n",
       "      <th>16190</th>\n",
       "      <th>16191</th>\n",
       "      <th>16192</th>\n",
       "      <th>16193</th>\n",
       "      <th>16194</th>\n",
       "      <th>16195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.016126</td>\n",
       "      <td>-0.089052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.00812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.019261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075050</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.041563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 16196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1         2         3      4         5      6         7      \\\n",
       "0   -0.00000   -0.0 -0.016126 -0.089052    0.0  0.000000   -0.0 -0.000000   \n",
       "1   -0.00000   -0.0 -0.000000 -0.000000    0.0  0.000000   -0.0 -0.000000   \n",
       "2    0.00000   -0.0  0.000000  0.000000   -0.0 -0.000000   -0.0  0.000000   \n",
       "3    0.00000   -0.0 -0.000000  0.000000   -0.0 -0.000000   -0.0  0.111724   \n",
       "4   -0.00000    0.0  0.000000 -0.000000    0.0  0.000000    0.0 -0.000000   \n",
       "..       ...    ...       ...       ...    ...       ...    ...       ...   \n",
       "994 -0.00000   -0.0 -0.000000 -0.000000    0.0  0.000000   -0.0 -0.000000   \n",
       "995  0.00000    0.0  0.000000 -0.000000    0.0  0.000000    0.0 -0.000000   \n",
       "996 -0.00812    0.0  0.000000 -0.000000    0.0  0.000000    0.0 -0.000000   \n",
       "997 -0.00000   -0.0  0.000000 -0.040840    0.0  0.000000   -0.0  0.019261   \n",
       "998  0.00000    0.0  0.000000  0.075050   -0.0  0.041563    0.0 -0.000000   \n",
       "\n",
       "     8      9      ...  16186  16187  16188  16189     16190  16191     16192  \\\n",
       "0      0.0   -0.0  ...   -0.0    0.0    0.0    0.0  0.000000   -0.0  0.011252   \n",
       "1      0.0   -0.0  ...   -0.0    0.0    0.0    0.0  0.000000   -0.0  0.000000   \n",
       "2      0.0    0.0  ...    0.0   -0.0   -0.0    0.0 -0.000000    0.0 -0.000000   \n",
       "3      0.0    0.0  ...    0.0    0.0   -0.0    0.0  0.030965    0.0  0.000000   \n",
       "4     -0.0    0.0  ...   -0.0    0.0   -0.0   -0.0  0.000000   -0.0  0.000000   \n",
       "..     ...    ...  ...    ...    ...    ...    ...       ...    ...       ...   \n",
       "994    0.0   -0.0  ...    0.0    0.0    0.0    0.0  0.000000   -0.0 -0.000000   \n",
       "995   -0.0    0.0  ...   -0.0    0.0   -0.0   -0.0  0.000000   -0.0  0.000000   \n",
       "996    0.0   -0.0  ...   -0.0   -0.0    0.0    0.0 -0.000000   -0.0  0.000000   \n",
       "997    0.0    0.0  ...    0.0    0.0   -0.0   -0.0 -0.000000   -0.0 -0.000000   \n",
       "998   -0.0    0.0  ...    0.0   -0.0    0.0   -0.0  0.000000   -0.0  0.000000   \n",
       "\n",
       "     16193  16194  16195  \n",
       "0      0.0   -0.0    0.0  \n",
       "1      0.0   -0.0    0.0  \n",
       "2     -0.0    0.0   -0.0  \n",
       "3     -0.0    0.0   -0.0  \n",
       "4      0.0   -0.0   -0.0  \n",
       "..     ...    ...    ...  \n",
       "994   -0.0   -0.0    0.0  \n",
       "995    0.0   -0.0   -0.0  \n",
       "996    0.0   -0.0    0.0  \n",
       "997   -0.0    0.0   -0.0  \n",
       "998   -0.0   -0.0   -0.0  \n",
       "\n",
       "[999 rows x 16196 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df = pd.DataFrame(attributions.detach().numpy())\n",
    "int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_class = np.where(final_preds==0)[0]\n",
    "avg_zero = torch.mean(attributions[zero_class,:], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gene3437     1.781654\n",
       "Gene15390    1.502186\n",
       "Gene32664    1.406374\n",
       "Gene13270    1.229324\n",
       "Gene30144    1.099090\n",
       "               ...   \n",
       "Gene3116    -0.443790\n",
       "Gene3915    -0.464828\n",
       "Gene26241   -0.566932\n",
       "Gene29925   -0.801099\n",
       "Gene22733   -0.909356\n",
       "Length: 16196, dtype: float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=avg_zero.detach().numpy(), index=gene_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/daniel/miniconda3/envs/thesis/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "int_df = utilities.run_interpretation_new(seq, X, final_preds, gene_names, 50, m.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gene3437</th>\n",
       "      <td>tensor(1.7817)</td>\n",
       "      <td>tensor(-0.2752)</td>\n",
       "      <td>tensor(-0.3625)</td>\n",
       "      <td>tensor(-0.4078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene15390</th>\n",
       "      <td>tensor(1.5022)</td>\n",
       "      <td>tensor(-0.3361)</td>\n",
       "      <td>tensor(-0.2582)</td>\n",
       "      <td>tensor(-0.4191)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene32664</th>\n",
       "      <td>tensor(1.4064)</td>\n",
       "      <td>tensor(-0.1714)</td>\n",
       "      <td>tensor(-0.1545)</td>\n",
       "      <td>tensor(-0.2735)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene13270</th>\n",
       "      <td>tensor(1.2293)</td>\n",
       "      <td>tensor(-0.1493)</td>\n",
       "      <td>tensor(-0.4300)</td>\n",
       "      <td>tensor(-0.1779)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene30144</th>\n",
       "      <td>tensor(1.0991)</td>\n",
       "      <td>tensor(-0.6028)</td>\n",
       "      <td>tensor(-0.2078)</td>\n",
       "      <td>tensor(0.0219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene3116</th>\n",
       "      <td>tensor(-0.4438)</td>\n",
       "      <td>tensor(2.4696)</td>\n",
       "      <td>tensor(-0.1610)</td>\n",
       "      <td>tensor(-0.6108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene3915</th>\n",
       "      <td>tensor(-0.4648)</td>\n",
       "      <td>tensor(0.8291)</td>\n",
       "      <td>tensor(0.7450)</td>\n",
       "      <td>tensor(-0.4540)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene26241</th>\n",
       "      <td>tensor(-0.5669)</td>\n",
       "      <td>tensor(-0.3661)</td>\n",
       "      <td>tensor(-0.2608)</td>\n",
       "      <td>tensor(1.1565)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene29925</th>\n",
       "      <td>tensor(-0.8011)</td>\n",
       "      <td>tensor(0.5427)</td>\n",
       "      <td>tensor(0.2662)</td>\n",
       "      <td>tensor(0.5778)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene22733</th>\n",
       "      <td>tensor(-0.9094)</td>\n",
       "      <td>tensor(-0.6818)</td>\n",
       "      <td>tensor(-0.7434)</td>\n",
       "      <td>tensor(1.9261)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16196 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                1                2                3\n",
       "Gene3437    tensor(1.7817)  tensor(-0.2752)  tensor(-0.3625)  tensor(-0.4078)\n",
       "Gene15390   tensor(1.5022)  tensor(-0.3361)  tensor(-0.2582)  tensor(-0.4191)\n",
       "Gene32664   tensor(1.4064)  tensor(-0.1714)  tensor(-0.1545)  tensor(-0.2735)\n",
       "Gene13270   tensor(1.2293)  tensor(-0.1493)  tensor(-0.4300)  tensor(-0.1779)\n",
       "Gene30144   tensor(1.0991)  tensor(-0.6028)  tensor(-0.2078)   tensor(0.0219)\n",
       "...                    ...              ...              ...              ...\n",
       "Gene3116   tensor(-0.4438)   tensor(2.4696)  tensor(-0.1610)  tensor(-0.6108)\n",
       "Gene3915   tensor(-0.4648)   tensor(0.8291)   tensor(0.7450)  tensor(-0.4540)\n",
       "Gene26241  tensor(-0.5669)  tensor(-0.3661)  tensor(-0.2608)   tensor(1.1565)\n",
       "Gene29925  tensor(-0.8011)   tensor(0.5427)   tensor(0.2662)   tensor(0.5778)\n",
       "Gene22733  tensor(-0.9094)  tensor(-0.6818)  tensor(-0.7434)   tensor(1.9261)\n",
       "\n",
       "[16196 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gene33251</th>\n",
       "      <td>4.290428</td>\n",
       "      <td>-1.682135</td>\n",
       "      <td>-1.897375</td>\n",
       "      <td>-1.908934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene32664</th>\n",
       "      <td>2.917032</td>\n",
       "      <td>-1.377862</td>\n",
       "      <td>-1.515536</td>\n",
       "      <td>-1.983209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene3437</th>\n",
       "      <td>2.906509</td>\n",
       "      <td>-0.978128</td>\n",
       "      <td>-1.546086</td>\n",
       "      <td>-1.582908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene13270</th>\n",
       "      <td>2.631295</td>\n",
       "      <td>-0.538067</td>\n",
       "      <td>-2.414461</td>\n",
       "      <td>-1.117767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene15390</th>\n",
       "      <td>2.622656</td>\n",
       "      <td>-0.850041</td>\n",
       "      <td>-0.923804</td>\n",
       "      <td>-1.285519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene26241</th>\n",
       "      <td>-1.991125</td>\n",
       "      <td>-1.709032</td>\n",
       "      <td>-1.298382</td>\n",
       "      <td>3.995141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene20573</th>\n",
       "      <td>-2.011701</td>\n",
       "      <td>1.140697</td>\n",
       "      <td>1.194331</td>\n",
       "      <td>0.440151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene3915</th>\n",
       "      <td>-2.050619</td>\n",
       "      <td>3.413482</td>\n",
       "      <td>3.420287</td>\n",
       "      <td>-2.445457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene22733</th>\n",
       "      <td>-2.073040</td>\n",
       "      <td>-2.156051</td>\n",
       "      <td>-1.995495</td>\n",
       "      <td>4.689560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene29925</th>\n",
       "      <td>-4.153213</td>\n",
       "      <td>2.049893</td>\n",
       "      <td>1.936789</td>\n",
       "      <td>2.787995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16196 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3\n",
       "Gene33251  4.290428 -1.682135 -1.897375 -1.908934\n",
       "Gene32664  2.917032 -1.377862 -1.515536 -1.983209\n",
       "Gene3437   2.906509 -0.978128 -1.546086 -1.582908\n",
       "Gene13270  2.631295 -0.538067 -2.414461 -1.117767\n",
       "Gene15390  2.622656 -0.850041 -0.923804 -1.285519\n",
       "...             ...       ...       ...       ...\n",
       "Gene26241 -1.991125 -1.709032 -1.298382  3.995141\n",
       "Gene20573 -2.011701  1.140697  1.194331  0.440151\n",
       "Gene3915  -2.050619  3.413482  3.420287 -2.445457\n",
       "Gene22733 -2.073040 -2.156051 -1.995495  4.689560\n",
       "Gene29925 -4.153213  2.049893  1.936789  2.787995\n",
       "\n",
       "[16196 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_int_df.sort_values(by=0, ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

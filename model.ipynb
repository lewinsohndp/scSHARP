{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/.conda/envs/daniel_thesis_2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gcn_model import GCNModel\n",
    "import utilities\n",
    "from test_model import test_model\n",
    "import os\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\"\n",
    "#data_folder = \"simulations/splat_0.7_de_rq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(data_folder + \"preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "data_path = data_folder + \"query_counts.csv\"\n",
    "tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "#tools = [\"scsorter\",\"scina\",\"singler\"]\n",
    "ref_path = data_folder + \"ref_counts.csv\"\n",
    "ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "marker_path = data_folder + \"markers.txt\"\n",
    "if os.path.exists(data_folder + \"preds.csv\"):\n",
    "    all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "    if all_labels.shape[1] != len(tools): \n",
    "        all_labels = all_labels[tools]\n",
    "        #raise Exception(\"wrong amount of tools in file\")\n",
    "else:\n",
    "    all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scina</th>\n",
       "      <th>scsorter</th>\n",
       "      <th>sctype</th>\n",
       "      <th>singler</th>\n",
       "      <th>scpred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cell1001</th>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1002</th>\n",
       "      <td>Group4</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1003</th>\n",
       "      <td>Group1</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1004</th>\n",
       "      <td>Group4</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1005</th>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1996</th>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1997</th>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "      <td>Group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1998</th>\n",
       "      <td>Group3</td>\n",
       "      <td>Group3</td>\n",
       "      <td>Group3</td>\n",
       "      <td>Group3</td>\n",
       "      <td>Group3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell1999</th>\n",
       "      <td>Group4</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group4</td>\n",
       "      <td>Group4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell2000</th>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>Group2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           scina scsorter  sctype singler  scpred\n",
       "Cell1001  Group2   Group2  Group2  Group2  Group2\n",
       "Cell1002  Group4   Group2  Group2  Group4  Group2\n",
       "Cell1003  Group1   Group4  Group2  Group2     NaN\n",
       "Cell1004  Group4   Group4  Group4  Group4  Group1\n",
       "Cell1005  Group1   Group1  Group1  Group1  Group1\n",
       "...          ...      ...     ...     ...     ...\n",
       "Cell1996  Group2   Group2  Group4  Group2  Group1\n",
       "Cell1997  Group1   Group1  Group1  Group1  Group1\n",
       "Cell1998  Group3   Group3  Group3  Group3  Group3\n",
       "Cell1999  Group4   Group4  Group2  Group4  Group4\n",
       "Cell2000  Group2   Group2  Group2  Group2     NaN\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataset\n",
    "X = pd.read_csv(data_path, index_col=0)\n",
    "X, keep_cells = utilities.preprocess(np.array(X), scale=False)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.loc[keep_cells,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Group1', 'Group2', 'Group3', 'Group4']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,marker_names = utilities.read_marker_file(marker_path)\n",
    "marker_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell1001    Group2\n",
       "Cell1002    Group2\n",
       "Cell1003    Group4\n",
       "Cell1004    Group4\n",
       "Cell1005    Group1\n",
       "             ...  \n",
       "Cell1996    Group2\n",
       "Cell1997    Group1\n",
       "Cell1998    Group3\n",
       "Cell1999    Group4\n",
       "Cell2000    Group2\n",
       "Name: scsorter, Length: 999, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels['scsorter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 5., 0., 0.],\n",
       "       [0., 3., 0., 2.],\n",
       "       [1., 2., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 5., 0.],\n",
       "       [0., 1., 0., 4.],\n",
       "       [0., 4., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = data_folder + \"query_meta.csv\"\n",
    "metadata = pd.read_csv(meta_path, index_col=0)\n",
    "real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "real_y = real_y[keep_cells]\n",
    "real_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_y[real_y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792792797088623\n",
      "0.8138138055801392\n",
      "0.826826810836792\n",
      "0.8408408164978027\n",
      "0.6386386156082153\n"
     ]
    }
   ],
   "source": [
    "print(utilities.pred_accuracy(all_labels_factored['scina'], real_y))\n",
    "print(utilities.pred_accuracy(all_labels_factored['sctype'], real_y))\n",
    "print(utilities.pred_accuracy(all_labels_factored['scsorter'], real_y))\n",
    "print(utilities.pred_accuracy(all_labels_factored['singler'], real_y))\n",
    "print(utilities.pred_accuracy(all_labels_factored['scpred'], real_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/scSHARP/utilities.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return float((torch.tensor(preds) == torch.tensor(real)).type(torch.FloatTensor).mean().numpy())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9309309124946594"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pred = torch.tensor(encoded_labels).max(dim=1)[1]\n",
    "utilities.pred_accuracy(max_pred, real_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "confident_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  1.  2.  3.]\n",
      "[0. 1. 2. 3.]\n",
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "train_nodes = np.where(confident_labels != -1)[0]\n",
    "test_nodes = np.where(confident_labels == -1)[0]\n",
    "print(np.unique(confident_labels))\n",
    "print(np.unique(confident_labels[train_nodes]))\n",
    "print(np.unique(confident_labels[test_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 0, 0, 0, 1, 2, 2, 2, 3, 0, 1, 1, 3, 2, 0, 1, 2, 3, 2, 1,\n",
       "       0, 3, 3, 0, 3, 1, 2, 1, 1, 0, 0, 3, 2, 0, 0, 1, 2, 2, 0, 1, 1, 3,\n",
       "       2, 0, 0, 0, 0, 3, 3, 3, 0, 3, 1, 0, 3, 3, 0, 1, 2, 2, 0, 2, 1, 0,\n",
       "       3, 1, 0, 0, 2, 1, 3, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 3, 0, 2, 3, 0,\n",
       "       1, 2, 3, 2, 2, 2, 2, 0, 3, 0, 2, 3, 3, 2, 2, 0, 0, 2, 2, 0, 0, 0,\n",
       "       3, 1, 2, 2, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9724972248077393\n"
     ]
    }
   ],
   "source": [
    "print(utilities.pred_accuracy(confident_labels[train_nodes], real_y[train_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23333333432674408\n",
      "0.4555555582046509\n",
      "0.35555556416511536\n",
      "0.46666666865348816\n",
      "0.2222222238779068\n",
      "0.5111111402511597\n"
     ]
    }
   ],
   "source": [
    "# tool accuracy on test\n",
    "print(utilities.pred_accuracy(np.array(all_labels_factored['scina'][test_nodes]), real_y[test_nodes]))\n",
    "print(utilities.pred_accuracy(np.array(all_labels_factored['sctype'][test_nodes]), real_y[test_nodes]))\n",
    "print(utilities.pred_accuracy(np.array(all_labels_factored['scsorter'][test_nodes]), real_y[test_nodes]))\n",
    "print(utilities.pred_accuracy(np.array(all_labels_factored['singler'][test_nodes]), real_y[test_nodes]))\n",
    "print(utilities.pred_accuracy(np.array(all_labels_factored['scpred'][test_nodes]), real_y[test_nodes]))\n",
    "max_pred = torch.tensor(encoded_labels).max(dim=1)[1]\n",
    "print(utilities.pred_accuracy(max_pred[test_nodes], real_y[test_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=35, shuffle=True)\n",
    "\n",
    "test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=35, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GCNModel(\"configs/3_25.txt\", 2, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 36.518837\n",
      "Loss in epoch 10 = 0.023115\n",
      "Loss in epoch 20 = 0.006610\n",
      "Loss in epoch 30 = 0.001642\n",
      "Loss in epoch 40 = 0.001037\n",
      "Loss in epoch 50 = 0.000560\n",
      "Loss in epoch 60 = 0.000466\n",
      "Loss in epoch 70 = 0.000263\n",
      "Loss in epoch 80 = 0.000593\n",
      "Loss in epoch 90 = 0.000179\n",
      "Loss in epoch 100 = 0.000171\n",
      "Loss in epoch 110 = 0.000103\n",
      "Loss in epoch 120 = 0.000110\n",
      "Loss in epoch 130 = 0.000090\n",
      "Loss in epoch 140 = 0.000041\n",
      "Loss in epoch 150 = 0.000036\n",
      "Loss in epoch 160 = 0.000035\n",
      "Loss in epoch 170 = 0.000045\n",
      "Loss in epoch 180 = 0.000042\n",
      "Loss in epoch 190 = 0.000014\n"
     ]
    }
   ],
   "source": [
    "m.train(dataloader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9619619846343994,\n",
       " array([[219,   7,   4,   2],\n",
       "        [  1, 265,   2,   0],\n",
       "        [  2,   3, 225,   4],\n",
       "        [  2,   6,   5, 252]]),\n",
       " 0.9724972248077393,\n",
       " array([[178,   6,   2,   2],\n",
       "        [  0, 264,   2,   0],\n",
       "        [  1,   2, 211,   1],\n",
       "        [  0,   5,   4, 231]]),\n",
       " 0.855555534362793,\n",
       " array([[41,  1,  2,  0],\n",
       "        [ 1,  1,  0,  0],\n",
       "        [ 1,  1, 14,  3],\n",
       "        [ 2,  1,  1, 21]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.validation_metrics(test_dataloader, train_nodes, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start putting labels back in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = [\"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.6_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.8_de_rq/\"]\n",
    "#data_folders = [\"simulations/splat_0.6_de_rq/\", \"simulations/splat_0.7_de_rq/\", \"simulations/splat_0.8_de_rq/\"]\n",
    "#data_folders = [\"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\"]\n",
    "tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "votes_necessary = 3\n",
    "model_file = \"configs/2_25.txt\"\n",
    "neighbors = 2\n",
    "batch_size=20\n",
    "training_epochs=150\n",
    "random_inits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7839999794960022, 0.7870000004768372, 0.7919999957084656, 0.777999997138977, 0.7749999761581421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/scSHARP/utilities.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return float((torch.tensor(preds) == torch.tensor(real)).type(torch.FloatTensor).mean().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9639639854431152, 0.9619619846343994, 0.9629629850387573, 0.9619619846343994, 0.9599599838256836]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/scSHARP/utilities.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return float((torch.tensor(preds) == torch.tensor(real)).type(torch.FloatTensor).mean().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9869869947433472, 0.9879879951477051, 0.9869869947433472, 0.9869869947433472, 0.9879879951477051]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lewinsda/scSHARP/utilities.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return float((torch.tensor(preds) == torch.tensor(real)).type(torch.FloatTensor).mean().numpy())\n"
     ]
    }
   ],
   "source": [
    "results = test_model(data_folders, tools, votes_necessary, model_file, neighbors, batch_size, training_epochs, random_inits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>method</th>\n",
       "      <th>total_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>total_sd</th>\n",
       "      <th>train_sd</th>\n",
       "      <th>test_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>GCN</td>\n",
       "      <td>0.783200</td>\n",
       "      <td>0.920684</td>\n",
       "      <td>0.535574</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>Max Col.</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.920684</td>\n",
       "      <td>0.560224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>Confident Labels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>sctype</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.443235</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>scsorter</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.861586</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>scina</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.645412</td>\n",
       "      <td>0.145658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>singler</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.917574</td>\n",
       "      <td>0.700280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>splat_0.6_de_rq</td>\n",
       "      <td>scpred</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>GCN</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.972497</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>Max Col.</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.972497</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>Confident Labels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>sctype</td>\n",
       "      <td>0.813814</td>\n",
       "      <td>0.849285</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>scsorter</td>\n",
       "      <td>0.826827</td>\n",
       "      <td>0.873487</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>scina</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.848185</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>singler</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>0.877888</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>splat_0.7_de_rq</td>\n",
       "      <td>scpred</td>\n",
       "      <td>0.638639</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>GCN</td>\n",
       "      <td>0.987387</td>\n",
       "      <td>0.990702</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>Max Col.</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.990702</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>Confident Labels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>sctype</td>\n",
       "      <td>0.922923</td>\n",
       "      <td>0.934917</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>scsorter</td>\n",
       "      <td>0.906907</td>\n",
       "      <td>0.923554</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>scina</td>\n",
       "      <td>0.854855</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>singler</td>\n",
       "      <td>0.870871</td>\n",
       "      <td>0.887397</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>splat_0.8_de_rq</td>\n",
       "      <td>scpred</td>\n",
       "      <td>0.769770</td>\n",
       "      <td>0.786157</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data_name            method  total_accuracy  train_accuracy  \\\n",
       "0  splat_0.6_de_rq               GCN        0.783200        0.920684   \n",
       "1  splat_0.6_de_rq          Max Col.        0.792000        0.920684   \n",
       "2  splat_0.6_de_rq  Confident Labels             NaN        0.920684   \n",
       "3  splat_0.6_de_rq            sctype        0.301000        0.443235   \n",
       "4  splat_0.6_de_rq          scsorter        0.677000        0.861586   \n",
       "5  splat_0.6_de_rq             scina        0.467000        0.645412   \n",
       "6  splat_0.6_de_rq           singler        0.840000        0.917574   \n",
       "7  splat_0.6_de_rq            scpred        0.503000        0.626750   \n",
       "0  splat_0.7_de_rq               GCN        0.962162        0.972497   \n",
       "1  splat_0.7_de_rq          Max Col.        0.930931        0.972497   \n",
       "2  splat_0.7_de_rq  Confident Labels             NaN        0.972497   \n",
       "3  splat_0.7_de_rq            sctype        0.813814        0.849285   \n",
       "4  splat_0.7_de_rq          scsorter        0.826827        0.873487   \n",
       "5  splat_0.7_de_rq             scina        0.792793        0.848185   \n",
       "6  splat_0.7_de_rq           singler        0.840841        0.877888   \n",
       "7  splat_0.7_de_rq            scpred        0.638639        0.679868   \n",
       "0  splat_0.8_de_rq               GCN        0.987387        0.990702   \n",
       "1  splat_0.8_de_rq          Max Col.        0.973974        0.990702   \n",
       "2  splat_0.8_de_rq  Confident Labels             NaN        0.990702   \n",
       "3  splat_0.8_de_rq            sctype        0.922923        0.934917   \n",
       "4  splat_0.8_de_rq          scsorter        0.906907        0.923554   \n",
       "5  splat_0.8_de_rq             scina        0.854855        0.880165   \n",
       "6  splat_0.8_de_rq           singler        0.870871        0.887397   \n",
       "7  splat_0.8_de_rq            scpred        0.769770        0.786157   \n",
       "\n",
       "   test_accuracy  total_sd  train_sd   test_sd  \n",
       "0       0.535574  0.006834       0.0  0.019142  \n",
       "1       0.560224  0.000000       0.0  0.000000  \n",
       "2            NaN  0.000000       0.0  0.000000  \n",
       "3       0.044818  0.000000       0.0  0.000000  \n",
       "4       0.344538  0.000000       0.0  0.000000  \n",
       "5       0.145658  0.000000       0.0  0.000000  \n",
       "6       0.700280  0.000000       0.0  0.000000  \n",
       "7       0.280112  0.000000       0.0  0.000000  \n",
       "0       0.857778  0.001485       0.0  0.016480  \n",
       "1       0.511111  0.000000       0.0  0.000000  \n",
       "2            NaN  0.000000       0.0  0.000000  \n",
       "3       0.455556  0.000000       0.0  0.000000  \n",
       "4       0.355556  0.000000       0.0  0.000000  \n",
       "5       0.233333  0.000000       0.0  0.000000  \n",
       "6       0.466667  0.000000       0.0  0.000000  \n",
       "7       0.222222  0.000000       0.0  0.000000  \n",
       "0       0.883871  0.000548       0.0  0.017668  \n",
       "1       0.451613  0.000000       0.0  0.000000  \n",
       "2            NaN  0.000000       0.0  0.000000  \n",
       "3       0.548387  0.000000       0.0  0.000000  \n",
       "4       0.387097  0.000000       0.0  0.000000  \n",
       "5       0.064516  0.000000       0.0  0.000000  \n",
       "6       0.354839  0.000000       0.0  0.000000  \n",
       "7       0.258065  0.000000       0.0  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results from no feed forward or gcn labels\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 500)\n",
      "0.6011204719543457\n",
      "0.026691604570561273\n",
      "(999, 500)\n",
      "0.848888885974884\n",
      "0.023040499079638933\n",
      "(999, 500)\n",
      "0.7612903237342834\n",
      "0.02885248584038609\n"
     ]
    }
   ],
   "source": [
    "# test putting labels back in\n",
    "random_inits = 5\n",
    "data_folders = [\"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.6_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.8_de_rq/\"]\n",
    "for data_folder in data_folders:\n",
    "    data_path = data_folder + \"query_counts.csv\"\n",
    "    X = pd.read_csv(data_path, index_col=0)\n",
    "    X, keep_cells = utilities.preprocess(np.array(X), scale=False)\n",
    "    print(X.shape)\n",
    "    marker_path = data_folder + \"markers.txt\"\n",
    "    _,marker_names = utilities.read_marker_file(marker_path)\n",
    "    \n",
    "    meta_path = data_folder + \"query_meta.csv\"\n",
    "    metadata = pd.read_csv(meta_path, index_col=0)\n",
    "    real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "    real_y = real_y[keep_cells]\n",
    "    real_y.shape\n",
    "    \n",
    "    test_accuracy = [0]*random_inits\n",
    "    for i in range(random_inits):\n",
    "        tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "        #tools = [\"scsorter\",\"scina\",\"singler\"]\n",
    "        ref_path = data_folder + \"ref_counts.csv\"\n",
    "        ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "        \n",
    "        if os.path.exists(data_folder + \"preds.csv\"):\n",
    "            all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "            if all_labels.shape[1] != len(tools): \n",
    "                all_labels = all_labels[tools]\n",
    "                #raise Exception(\"wrong amount of tools in file\")\n",
    "        else:\n",
    "            all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)\n",
    "\n",
    "        all_labels = all_labels.loc[keep_cells,:]\n",
    "        all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "        encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "        confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "        train_nodes = np.where(confident_labels != -1)[0]\n",
    "        original_test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n",
    "        dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "        test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "        \n",
    "        m = GCNModel(\"configs/2_25.txt\", 2, dropout=0.0)\n",
    "        m.train(dataloader, 150, verbose = False)\n",
    "        \n",
    "        new_labels, _ = m.predict(test_dataloader)\n",
    "        new_labels = new_labels.max(dim=1)[1]\n",
    "        \n",
    "        #print(len(original_test_nodes))\n",
    "        for j in range(1,5):\n",
    "            col_name = \"gcn\" + str(j)\n",
    "            all_labels_factored[col_name] = new_labels.cpu()\n",
    "            encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "            confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "            train_nodes = np.where(confident_labels != -1)[0]\n",
    "            test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n",
    "            dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "            dataloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "            test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "            #print(len(test_nodes))\n",
    "\n",
    "            #m = GCNModel(\"configs/2_15.txt\", 2, dropout=0.0)\n",
    "            m.train(dataloader, 50, verbose=False)\n",
    "            #print(m.validation_metrics(test_dataloader, train_nodes, test_nodes))\n",
    "\n",
    "            new_labels, _ = m.predict(test_dataloader)\n",
    "            new_labels = new_labels.max(dim=1)[1]\n",
    "            \n",
    "        _,_,_,_,accuracy,_ = m.validation_metrics(test_dataloader, train_nodes, original_test_nodes)\n",
    "        test_accuracy[i] = accuracy\n",
    "    print(statistics.mean(test_accuracy))\n",
    "    print(statistics.stdev(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 500)\n",
      "0.6302521228790283\n",
      "0.014005601406097412\n",
      "(999, 500)\n",
      "0.8814814885457357\n",
      "0.03394500312454106\n",
      "(999, 500)\n",
      "0.8387096722920736\n",
      "0.08534682520664126\n"
     ]
    }
   ],
   "source": [
    "# test putting labels back in new model each time\n",
    "random_inits = 3\n",
    "data_folders = [\"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.6_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.7_de_rq/\", \"/home/groups/ConradLab/daniel/sharp_data/sharp_sims/splat_0.8_de_rq/\"]\n",
    "for data_folder in data_folders:\n",
    "    data_path = data_folder + \"query_counts.csv\"\n",
    "    X = pd.read_csv(data_path, index_col=0)\n",
    "    X, keep_cells = utilities.preprocess(np.array(X), scale=False)\n",
    "    print(X.shape)\n",
    "    marker_path = data_folder + \"markers.txt\"\n",
    "    _,marker_names = utilities.read_marker_file(marker_path)\n",
    "    \n",
    "    meta_path = data_folder + \"query_meta.csv\"\n",
    "    metadata = pd.read_csv(meta_path, index_col=0)\n",
    "    real_y = pd.factorize(metadata['Group'], sort=True)[0]\n",
    "    real_y = real_y[keep_cells]\n",
    "    real_y.shape\n",
    "    \n",
    "    test_accuracy = [0]*random_inits\n",
    "    for i in range(random_inits):\n",
    "        tools = [\"sctype\",\"scsorter\",\"scina\",\"singler\", \"scpred\"]\n",
    "        #tools = [\"scsorter\",\"scina\",\"singler\"]\n",
    "        ref_path = data_folder + \"ref_counts.csv\"\n",
    "        ref_label_path = data_folder + \"ref_labels.csv\"\n",
    "        \n",
    "        if os.path.exists(data_folder + \"preds.csv\"):\n",
    "            all_labels = pd.read_csv(data_folder + \"preds.csv\", index_col=0)\n",
    "            if all_labels.shape[1] != len(tools): \n",
    "                all_labels = all_labels[tools]\n",
    "                #raise Exception(\"wrong amount of tools in file\")\n",
    "        else:\n",
    "            all_labels = utilities.label_counts(data_path,tools,ref_path,ref_label_path,marker_path)\n",
    "\n",
    "        all_labels = all_labels.loc[keep_cells,:]\n",
    "        all_labels_factored = utilities.factorize_df(all_labels, marker_names)\n",
    "        encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "        confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "        train_nodes = np.where(confident_labels != -1)[0]\n",
    "        original_test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n",
    "        dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "        test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "        \n",
    "        m = GCNModel(\"configs/2_25.txt\", 2, dropout=0.0)\n",
    "        m.train(dataloader, 150, verbose = False)\n",
    "        \n",
    "        new_labels, _ = m.predict(test_dataloader)\n",
    "        new_labels = new_labels.max(dim=1)[1]\n",
    "        \n",
    "        #print(len(original_test_nodes))\n",
    "        for j in range(1,5):\n",
    "            col_name = \"gcn\" + str(j)\n",
    "            all_labels_factored[col_name] = new_labels.cpu()\n",
    "            encoded_labels = utilities.encode_predictions(all_labels_factored)\n",
    "            confident_labels = utilities.get_consensus_labels(encoded_labels, necessary_vote = 3)\n",
    "            train_nodes = np.where(confident_labels != -1)[0]\n",
    "            test_nodes = np.where(confident_labels == -1)[0]\n",
    "\n",
    "            dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(confident_labels))\n",
    "            dataloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "            test_dataset  = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(real_y))\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "            #print(len(test_nodes))\n",
    "\n",
    "            m = GCNModel(\"configs/2_25.txt\", 2, dropout=0.0)\n",
    "            m.train(dataloader, 150, verbose=False)\n",
    "            #print(m.validation_metrics(test_dataloader, train_nodes, test_nodes))\n",
    "\n",
    "            new_labels, _ = m.predict(test_dataloader)\n",
    "            new_labels = new_labels.max(dim=1)[1]\n",
    "            \n",
    "        _,_,_,_,accuracy,_ = m.validation_metrics(test_dataloader, train_nodes, original_test_nodes)\n",
    "        test_accuracy[i] = accuracy\n",
    "    print(statistics.mean(test_accuracy))\n",
    "    print(statistics.stdev(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel_thesis",
   "language": "python",
   "name": "daniel_thesis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e461d02738fd757bc3d2933f9434d370f54d79aa7bbf71ca755487c9a10e111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
